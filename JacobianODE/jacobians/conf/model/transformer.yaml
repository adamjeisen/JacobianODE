params:
  # _partial_: True
  _target_: CommunicationJacobians.models.transformer.Transformer
  input_dim: null
  output_dim: null
  # d_model: 32
  # d_model: 128
  d_model: 512
  nhead: 8
  # nhead: 8
  # dim_feedforward: 512
  dim_feedforward: 2048
  num_encoder_layers: 4
  # num_encoder_layers: 4
  num_decoder_layers: 4
  # num_decoder_layers: 4
  # positional_embed: True
  positional_embed: False
  max_len: null
  activation: silu
  # dropout: 0.5
  dropout: 0.0
  causal: False